import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold
from sklearn.metrics import r2_score


️# 切分資料（固定 test，不參與調參）
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)

#️ 建立基礎模型
rf = RandomForestRegressor(
    random_state=42,
    n_jobs=-1
)


️# 設定搜尋空間
param_dist = {
    "n_estimators": [200, 300, 500, 800, 1000],
    "max_depth": [None, 3, 4, 5, 6, 8, 10],
    "min_samples_split": [2, 5, 10, 20],
    "min_samples_leaf": [1, 2, 4, 8],
    "max_features": ["sqrt", "log2", 0.5, 0.7, 1.0],
    "bootstrap": [True, False]
}


️# 交叉驗證設定
cv = KFold(
    n_splits=5,
    shuffle=True,
    random_state=42
)


# RandomizedSearch（以 R² 為優化指標）
search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=60,                # 可改 100 更準
    scoring="r2",             # ⭐ 核心：用 R²
    cv=cv,
    random_state=42,
    n_jobs=-1,
    verbose=2,
    return_train_score=True
)

# 開始搜尋
search.fit(X_train, y_train)


# 最佳結果
print("\nBest Parameters:")
print(search.best_params_)

print("\nBest CV R²:")
print(search.best_score_)


️# 在 Test 上評估
best_model = search.best_estimator_

y_train_pred = best_model.predict(X_train)
y_test_pred = best_model.predict(X_test)

r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

print("\nTrain R²:", r2_train)
print("Test  R²:", r2_test)
print("Overfitting Gap (Train - Test):", r2_train - r2_test)

import numpy as np
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# Spearman
def spearman_corr(y_true, y_pred):
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)

    # rank
    def rankdata(a):
        order = np.argsort(a)
        ranks = np.empty_like(order, dtype=float)
        ranks[order] = np.arange(len(a), dtype=float)
        # ties average
        _, inv, counts = np.unique(a, return_inverse=True, return_counts=True)
        sums = np.bincount(inv, ranks)
        avg = sums / counts
        return avg[inv]

    rt = rankdata(y_true)
    rp = rankdata(y_pred)

    # 皮爾森相關
    rt = rt - rt.mean()
    rp = rp - rp.mean()
    denom = np.sqrt((rt**2).sum() * (rp**2).sum())
    return float((rt * rp).sum() / denom) if denom != 0 else np.nan


def evaluate_with_best_params(
    model_type,                # "rf" 或 "gbr"
    best_params,               # dict：search.best_params_
    X, y,
    test_size=0.2,
    random_state=42,
    cv_splits=5
):
    """
    用最佳參數建模，輸出：
    RMSE, MAE, MedianAE, CV RMSE mean±std, Train-Test Gap, Spearman
    """

    # 1) 固定 test set（不參與 CV）
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    # 2) 建立模型
    if model_type == "rf":
        model = RandomForestRegressor(random_state=random_state, n_jobs=-1, **best_params)
    elif model_type == "gbr":
        model = GradientBoostingRegressor(random_state=random_state, **best_params)
    else:
        raise ValueError("model_type 只支援 'rf' 或 'gbr'")

    # 3) 訓練（用 train）
    model.fit(X_train, y_train)

    # 4) 預測（train/test）
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # 5) 指標：RMSE / MAE / MedianAE
    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))
    rmse_test  = np.sqrt(mean_squared_error(y_test, y_test_pred))

    mae_test = mean_absolute_error(y_test, y_test_pred)
    medae_test = median_absolute_error(y_test, y_test_pred)

    # 6) CV RMSE mean ± std
    cv = KFold(n_splits=cv_splits, shuffle=True, random_state=random_state)
    cv_scores = cross_val_score(
        model, X_train, y_train,
        scoring="neg_root_mean_squared_error",
        cv=cv,
        n_jobs=-1
    )
    cv_rmse = -cv_scores
    cv_rmse_mean = cv_rmse.mean()
    cv_rmse_std  = cv_rmse.std(ddof=1)

    # 7) Train–Test Gap（過擬合檢測）
    rmse_gap = rmse_test - rmse_train   # >0 通常代表 test 比 train 差（正常，但太大可能 overfit）

    # 8) Spearman rank correlation（排名一致性）
    spearman = spearman_corr(y_test, y_test_pred)

    # 9) 輸出
    print("\n==============================")
    print(f"Model: {model_type.upper()} | Best params: {best_params}")
    print("==============================")
    print(f"RMSE (test): {rmse_test:.6f}")
    print(f"MAE  (test): {mae_test:.6f}")
    print(f"MedianAE (test): {medae_test:.6f}")
    print(f"CV RMSE (train, {cv_splits}-fold): {cv_rmse_mean:.6f} ± {cv_rmse_std:.6f}")
    print(f"Train–Test Gap (RMSE_test - RMSE_train): {rmse_gap:.6f}")
    print(f"Spearman rank corr (test): {spearman:.6f}")

    # 回傳結果
    return {
        "rmse_test": rmse_test,
        "mae_test": mae_test,
        "medae_test": medae_test,
        "cv_rmse_mean": cv_rmse_mean,
        "cv_rmse_std": cv_rmse_std,
        "rmse_gap": rmse_gap,
        "spearman_test": spearman
    }

    best_params_rf = search.best_params_
results_rf = evaluate_with_best_params("rf", best_params_rf, X, y)
