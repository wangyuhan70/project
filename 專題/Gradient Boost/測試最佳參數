import numpy as np
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# Spearman
def spearman_corr(y_true, y_pred):
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)

    # rank
    def rankdata(a):
        order = np.argsort(a)
        ranks = np.empty_like(order, dtype=float)
        ranks[order] = np.arange(len(a), dtype=float)
        # ties average
        _, inv, counts = np.unique(a, return_inverse=True, return_counts=True)
        sums = np.bincount(inv, ranks)
        avg = sums / counts
        return avg[inv]

    rt = rankdata(y_true)
    rp = rankdata(y_pred)

    # 皮爾森相關
    rt = rt - rt.mean()
    rp = rp - rp.mean()
    denom = np.sqrt((rt**2).sum() * (rp**2).sum())
    return float((rt * rp).sum() / denom) if denom != 0 else np.nan


def evaluate_with_best_params(
    model_type,             
    best_params,             
    X, y,
    test_size=0.2,
    random_state=42,
    cv_splits=5
):
    """
    用最佳參數建模，輸出：
    RMSE, MAE, MedianAE, CV RMSE mean±std, Train-Test Gap, Spearman
    """

    # 1) 固定 test set（不參與 CV）
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    # 2) 建立模型
    if model_type == "rf":
        model = RandomForestRegressor(random_state=random_state, n_jobs=-1, **best_params)
    elif model_type == "gbr":
        model = GradientBoostingRegressor(random_state=random_state, **best_params)
    else:
        raise ValueError("model_type 只支援 'rf' 或 'gbr'")

    # 3) 訓練（用 train）
    model.fit(X_train, y_train)

    # 4) 預測（train/test）
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # 5) 指標：RMSE / MAE / MedianAE
    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))
    rmse_test  = np.sqrt(mean_squared_error(y_test, y_test_pred))

    mae_test = mean_absolute_error(y_test, y_test_pred)
    medae_test = median_absolute_error(y_test, y_test_pred)

    # 6) CV RMSE mean ± std
    cv = KFold(n_splits=cv_splits, shuffle=True, random_state=random_state)
    cv_scores = cross_val_score(
        model, X_train, y_train,
        scoring="neg_root_mean_squared_error",
        cv=cv,
        n_jobs=-1
    )
    cv_rmse = -cv_scores
    cv_rmse_mean = cv_rmse.mean()
    cv_rmse_std  = cv_rmse.std(ddof=1)

    # 7) Train–Test Gap（過擬合檢測）
    rmse_gap = rmse_test - rmse_train 

    # 8) Spearman rank correlation（排名一致性）
    spearman = spearman_corr(y_test, y_test_pred)

    # 9) 輸出
    print("\n==============================")
    print(f"Model: {model_type.upper()} | Best params: {best_params}")
    print("==============================")
    print(f"RMSE (test): {rmse_test:.6f}")
    print(f"MAE  (test): {mae_test:.6f}")
    print(f"MedianAE (test): {medae_test:.6f}")
    print(f"CV RMSE (train, {cv_splits}-fold): {cv_rmse_mean:.6f} ± {cv_rmse_std:.6f}")
    print(f"Train–Test Gap (RMSE_test - RMSE_train): {rmse_gap:.6f}")
    print(f"Spearman rank corr (test): {spearman:.6f}")

    # 回傳結果
    return {
        "rmse_test": rmse_test,
        "mae_test": mae_test,
        "medae_test": medae_test,
        "cv_rmse_mean": cv_rmse_mean,
        "cv_rmse_std": cv_rmse_std,
        "rmse_gap": rmse_gap,
        "spearman_test": spearman
    }
best_params_gbr = grid.best_params_
results_gbr = evaluate_with_best_params("gbr", best_params_gbr, X, y)
